{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt') # one time execution\n",
    "# nltk.download('stopwords')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Stories 92579\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import string\n",
    " \n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, encoding='utf-8')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    " \n",
    "# split a document into news story and highlights\n",
    "def split_story(doc):\n",
    "\t# find first highlight\n",
    "\tindex = doc.find('@highlight')\n",
    "\t# split into story and highlights\n",
    "\tstory, highlights = doc[:index], doc[index:].split('@highlight')\n",
    "\t# strip extra white space around each highlight\n",
    "\thighlights = [h.strip() for h in highlights if len(h) > 0]\n",
    "\treturn story, highlights\n",
    " \n",
    "# load all stories in a directory\n",
    "def load_stories(directory):\n",
    "\tstories = list()\n",
    "\tfor name in listdir(directory):\n",
    "\t\tfilename = directory + '/' + name\n",
    "\t\t# load document\n",
    "\t\tdoc = load_doc(filename)\n",
    "\t\t# split into story and highlights\n",
    "\t\tstory, highlights = split_story(doc)\n",
    "\t\t# store\n",
    "\t\tstories.append({'story':story, 'highlights':highlights})\n",
    "\treturn stories\n",
    " \n",
    "# clean a list of lines\n",
    "def clean_lines(lines):\n",
    "\tcleaned = list()\n",
    "\t# prepare a translation table to remove punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor line in lines:\n",
    "\t\t# strip source cnn office if it exists\n",
    "\t\tindex = line.find('(CNN) -- ')\n",
    "\t\tif index > -1:\n",
    "\t\t\tline = line[index+len('(CNN)'):]\n",
    "\t\t# tokenize on white space\n",
    "\t\tline = line.split()\n",
    "\t\t# convert to lower case\n",
    "\t\tline = [word.lower() for word in line]\n",
    "\t\t# remove punctuation from each token\n",
    "\t\tline = [w.translate(table) for w in line]\n",
    "\t\t# remove tokens with numbers in them\n",
    "\t\tline = [word for word in line if word.isalpha()]\n",
    "\t\t# store as string\n",
    "\t\tcleaned.append(' '.join(line))\n",
    "\t# remove empty strings\n",
    "\tcleaned = [c for c in cleaned if len(c) > 0]\n",
    "\treturn cleaned\n",
    " \n",
    "# load stories\n",
    "directory = 'cnn/stories/'\n",
    "stories = load_stories(directory)\n",
    "print('Loaded Stories %d' % len(stories))\n",
    " \n",
    "# clean stories\n",
    "for example in stories:\n",
    "\texample['story'] = clean_lines(example['story'].split('\\n'))\n",
    "\texample['highlights'] = clean_lines(example['highlights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Stories 92579\n"
     ]
    }
   ],
   "source": [
    "# save to file\n",
    "from pickle import dump\n",
    "import pickle\n",
    "\n",
    "# dump(stories, open('cnn_dataset.pkl', 'wb'))\n",
    "\n",
    "\n",
    "# load from file\n",
    "stories = pickle.load(open('cnn_dataset.pkl', 'rb'))\n",
    "print('Loaded Stories %d' % len(stories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highlights</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>syrian official obama climbed to the top of th...</td>\n",
       "      <td>its official us president barack obama wants l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usain bolt wins third gold of world championship</td>\n",
       "      <td>usain bolt rounded off the world championships...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the employee in agencys kansas city office is ...</td>\n",
       "      <td>the general services administration already un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new a canadian doctor says she was part of a t...</td>\n",
       "      <td>a medical doctor in vancouver british columbia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>another arrest made in gang rape outside calif...</td>\n",
       "      <td>police arrested another teen thursday the sixt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          highlights  \\\n",
       "0  syrian official obama climbed to the top of th...   \n",
       "1   usain bolt wins third gold of world championship   \n",
       "2  the employee in agencys kansas city office is ...   \n",
       "3  new a canadian doctor says she was part of a t...   \n",
       "4  another arrest made in gang rape outside calif...   \n",
       "\n",
       "                                               story  \n",
       "0  its official us president barack obama wants l...  \n",
       "1  usain bolt rounded off the world championships...  \n",
       "2  the general services administration already un...  \n",
       "3  a medical doctor in vancouver british columbia...  \n",
       "4  police arrested another teen thursday the sixt...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stories)\n",
    "df['story'] = df['story'].str[0]\n",
    "df['highlights'] = df['highlights'].str[0]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## understanding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape is : (92579, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "highlights      0\n",
       "story         114\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('the shape is :',df.shape)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92465, 2)\n"
     ]
    }
   ],
   "source": [
    "df.replace('', np.nan, inplace=True)\n",
    "df.dropna(axis=0,inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in df['story']:\n",
    "    text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in df['highlights']:\n",
    "    summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>92465.000000</td>\n",
       "      <td>92465.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.682388</td>\n",
       "      <td>11.405505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.218451</td>\n",
       "      <td>2.566899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>388.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text       summary\n",
       "count  92465.000000  92465.000000\n",
       "mean      28.682388     11.405505\n",
       "std       12.218451      2.566899\n",
       "min        1.000000      1.000000\n",
       "25%       22.000000     10.000000\n",
       "50%       28.000000     11.000000\n",
       "75%       34.000000     13.000000\n",
       "max      388.000000     39.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32569080192505273\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in df['highlights']:\n",
    "    if(len(i.split())>12) :\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(df['highlights']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3793327204888336\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in df['story']:\n",
    "    if(len(i.split())>30):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(df['story']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=150\n",
    "max_summary_len=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text =np.array(df['story'])\n",
    "cleaned_summary=np.array(df['highlights'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())>=12 and len(cleaned_text[i].split())>=30):\n",
    "       \n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "data=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['summary'] = data['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20399, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(data['text']),np.array(data['summary']),test_size=0.1,random_state=0,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of training data: 18359\n"
     ]
    }
   ],
   "source": [
    "print(\"the length of training data:\",len(x_tr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 65.6357293926992\n",
      "Total Coverage of rare words: 4.81357228958768\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary Tokenizer\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 78.77478811816012\n",
      "Total Coverage of rare words: 11.59361490787504\n"
     ]
    }
   ],
   "source": [
    "#rare words in summary\n",
    "\n",
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18359, 18359)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = []\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160\n",
      "18359\n",
      "2040\n",
      "18359\n",
      "2040\n",
      "12512\n"
     ]
    }
   ],
   "source": [
    "print(y_voc)\n",
    "print(len(y_tr))\n",
    "print(len(y_val))\n",
    "print(len(x_tr))\n",
    "print(len(x_val))\n",
    "print(x_voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 150, 100)     1251200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 150, 300), ( 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 150, 300), ( 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    516000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 150, 300), ( 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 5160)   3101160     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,453,460\n",
      "Trainable params: 7,453,460\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as Ke \n",
    "#import tensorflow.python.keras as K\n",
    "Ke.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU,PReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "learning_rate = 0.002\n",
    "clip_norm = 1.0\n",
    "\n",
    "rmsprop = RMSprop(lr=learning_rate,clipnorm=clip_norm)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18359 samples, validate on 2040 samples\n",
      "Epoch 1/19\n",
      "18359/18359 [==============================] - 520s 28ms/sample - loss: 3.0428 - accuracy: 0.5904 - val_loss: 2.7516 - val_accuracy: 0.6189\n",
      "Epoch 2/19\n",
      "18359/18359 [==============================] - 490s 27ms/sample - loss: 2.7639 - accuracy: 0.6154 - val_loss: 2.6710 - val_accuracy: 0.6234\n",
      "Epoch 3/19\n",
      "18359/18359 [==============================] - 491s 27ms/sample - loss: 2.6789 - accuracy: 0.6192 - val_loss: 2.5876 - val_accuracy: 0.6275\n",
      "Epoch 4/19\n",
      "18359/18359 [==============================] - 496s 27ms/sample - loss: 2.6020 - accuracy: 0.6241 - val_loss: 2.5290 - val_accuracy: 0.6330\n",
      "Epoch 5/19\n",
      "18359/18359 [==============================] - 497s 27ms/sample - loss: 2.5360 - accuracy: 0.6293 - val_loss: 2.4869 - val_accuracy: 0.6369\n",
      "Epoch 6/19\n",
      "18359/18359 [==============================] - 496s 27ms/sample - loss: 2.4810 - accuracy: 0.6335 - val_loss: 2.5637 - val_accuracy: 0.6331\n",
      "Epoch 7/19\n",
      "18359/18359 [==============================] - 490s 27ms/sample - loss: 2.4307 - accuracy: 0.6364 - val_loss: 2.4279 - val_accuracy: 0.6426\n",
      "Epoch 8/19\n",
      "18359/18359 [==============================] - 498s 27ms/sample - loss: 2.3830 - accuracy: 0.6388 - val_loss: 2.4063 - val_accuracy: 0.6439\n",
      "Epoch 9/19\n",
      "18359/18359 [==============================] - 488s 27ms/sample - loss: 2.3379 - accuracy: 0.6411 - val_loss: 2.3881 - val_accuracy: 0.6456\n",
      "Epoch 10/19\n",
      "18359/18359 [==============================] - 484s 26ms/sample - loss: 2.2950 - accuracy: 0.6435 - val_loss: 2.3780 - val_accuracy: 0.6451\n",
      "Epoch 11/19\n",
      "18359/18359 [==============================] - 487s 27ms/sample - loss: 2.2530 - accuracy: 0.6452 - val_loss: 2.3633 - val_accuracy: 0.6465\n",
      "Epoch 12/19\n",
      "18359/18359 [==============================] - 489s 27ms/sample - loss: 2.2140 - accuracy: 0.6469 - val_loss: 2.3507 - val_accuracy: 0.6484\n",
      "Epoch 13/19\n",
      "18359/18359 [==============================] - 490s 27ms/sample - loss: 2.1774 - accuracy: 0.6488 - val_loss: 2.3443 - val_accuracy: 0.6484\n",
      "Epoch 14/19\n",
      "18359/18359 [==============================] - 491s 27ms/sample - loss: 2.1414 - accuracy: 0.6506 - val_loss: 2.3426 - val_accuracy: 0.6482\n",
      "Epoch 15/19\n",
      "18359/18359 [==============================] - 486s 26ms/sample - loss: 2.1080 - accuracy: 0.6522 - val_loss: 2.3366 - val_accuracy: 0.6497\n",
      "Epoch 16/19\n",
      "18359/18359 [==============================] - 488s 27ms/sample - loss: 2.0757 - accuracy: 0.6540 - val_loss: 2.3371 - val_accuracy: 0.6503\n",
      "Epoch 17/19\n",
      "18359/18359 [==============================] - 489s 27ms/sample - loss: 2.0446 - accuracy: 0.6557 - val_loss: 2.3329 - val_accuracy: 0.6503\n",
      "Epoch 18/19\n",
      "18359/18359 [==============================] - 493s 27ms/sample - loss: 2.0142 - accuracy: 0.6575 - val_loss: 2.3334 - val_accuracy: 0.6505\n",
      "Epoch 19/19\n",
      "18359/18359 [==============================] - 489s 27ms/sample - loss: 1.9872 - accuracy: 0.6589 - val_loss: 2.3383 - val_accuracy: 0.6503\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=19,batch_size=100, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: as i raised my hands toward the ceiling and then pointed them toward my head i had to wonder how would the russian writer feel if he knew that a bunch of foreigners were dancing the at a nightclub named after him \n",
      "Original summary: the body of vladimir is on display in red square \n",
      "Predicted summary:  the is the first time in the world war\n",
      "\n",
      "\n",
      "Review: amanda knox describes her strange actions after her roommates murder as the behavior of a girl in a trauma during a wideranging and at times interview that aired tuesday \n",
      "Original summary: amanda knox tells abc that she wants to one day visit the of meredith kercher \n",
      "Predicted summary:  new the case of the victim is a of the case\n",
      "\n",
      "\n",
      "Review: cnn rafael nadal may be more used to serving than his stuff on a film set but that has not stopped the former world number one from appearing with colombian rock star in her new music video \n",
      "Original summary: tennis stars of past and present have turned their to land roles in films \n",
      "Predicted summary:  roger federer beats roger federer to reach the fourth round of the french open\n",
      "\n",
      "\n",
      "Review: this week the country witnessed one of the most irresponsible acts that we have seen from this republican congress since they deliberately shut down the government less than a year ago \n",
      "Original summary: maria cardona explains why republicans forced the president to act on immigration \n",
      "Predicted summary:  new the house committee will be a new gop to the senate\n",
      "\n",
      "\n",
      "Review: a lastditch effort to put an end to the bloodshed in syria failed on saturday with russia and china their veto at the united nations with that fateful decision the conflict moved to another more dangerous stage those who warn that syria will descend into civil war are a bit behind it is already in civil war now it will only \n",
      "Original summary: hamid the of the un resolution on syria send the conflict to a new more dangerous phase \n",
      "Predicted summary:  new the us and the syrian african leader is the first time\n",
      "\n",
      "\n",
      "Review: champions of equal protection had their day in court but it was a highly day in the supreme court unlike the interracial marriage case of loving v virginia the gay rights decision in united states v windsor while also a victory for civil rights is not a moment of legal clarity or in court windsor is closer to bush v gore \n",
      "Original summary: equality won for samesex marriage but it was far from a slam \n",
      "Predicted summary:  new the supreme court is a very step to the ruling\n",
      "\n",
      "\n",
      "Review: the body of a man whom authorities described as a disgruntled vendor who shot two people one fatally at a long island business last week was found dead monday according to nassau county police \n",
      "Original summary: kim suspected in a shooting at a long island business was found dead \n",
      "Predicted summary:  new police say they think the suspect was a police in the suspect\n",
      "\n",
      "\n",
      "Review: the democratic republic of the congo declared two days of mourning monday and tuesday for the victims of the massive oil tanker explosion that killed more than people over the weekend \n",
      "Original summary: at least killed by explosion in democratic republic of the congo \n",
      "Predicted summary:  new the gulf coast guard says the gulf oil spill will be\n",
      "\n",
      "\n",
      "Review: at least women and children were killed in the syrian city of homs late sunday opposition activists said hours after the un special envoy to syria met with the countrys president in an effort to reach a diplomatic solution to end the violence \n",
      "Original summary: new at least women and children are stabbed then burned activists say \n",
      "Predicted summary:  new the us is the first step to the gulf of the country\n",
      "\n",
      "\n",
      "Review: washington the senate expected to vote soon on the controversial keystone xl pipeline the state department is now giving eight federal agencies two weeks to weigh in on it \n",
      "Original summary: the senate is expected to vote soon on the controversial keystone xl pipeline \n",
      "Predicted summary:  the senate of the senate will vote on the country\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
